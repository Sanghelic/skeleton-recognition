{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XcL3tYDkZfmF",
        "outputId": "8a21e6f7-b8cf-4262-a4dd-5d955ccb14b7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "SKELETON_PKL_PATH = \"/content/drive/MyDrive/Colab Notebooks/ucf101_2d.pkl\"\n",
        "\n",
        "print(\"Existe:\", os.path.exists(SKELETON_PKL_PATH))\n",
        "print(\"Tamaño:\", os.path.getsize(SKELETON_PKL_PATH))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5VNC_UvtliqF",
        "outputId": "a404f006-e2fc-4bbb-dbf8-8da0b125aa1e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Existe: True\n",
            "Tamaño: 1070780736\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "\n",
        "with open(SKELETON_PKL_PATH, \"rb\") as f:\n",
        "    data = pickle.load(f)\n",
        "\n",
        "print(\"Keys en el dict:\", data.keys())\n",
        "\n",
        "split = data.get(\"split\", None)\n",
        "annotations = data.get(\"annotations\", None)\n",
        "\n",
        "print(\"Tipo de split:\", type(split))\n",
        "print(\"Tipo de annotations:\", type(annotations))\n",
        "print(\"Numero de anotaciones:\", len(annotations))\n",
        "\n",
        "print(\"\\nEjemplo de anotacion:\")\n",
        "example = annotations[0]\n",
        "for k, v in example.items():\n",
        "    if isinstance(v, np.ndarray):\n",
        "        print(f\"{k}: ndarray, shape = {v.shape}\")\n",
        "    else:\n",
        "        print(f\"{k}: {v}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJFXlNODlnev",
        "outputId": "88c90038-6777-46ce-8147-5d850517afde"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keys en el dict: dict_keys(['split', 'annotations'])\n",
            "Tipo de split: <class 'dict'>\n",
            "Tipo de annotations: <class 'list'>\n",
            "Numero de anotaciones: 13320\n",
            "\n",
            "Ejemplo de anotacion:\n",
            "keypoint: ndarray, shape = (1, 119, 17, 2)\n",
            "keypoint_score: ndarray, shape = (1, 119, 17)\n",
            "frame_dir: v_ApplyEyeMakeup_g08_c01\n",
            "total_frames: 119\n",
            "original_shape: (256, 340)\n",
            "img_shape: (256, 340)\n",
            "label: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import numpy as np\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Device:\", DEVICE)\n",
        "\n",
        "MAX_FRAMES = 60\n",
        "BATCH_SIZE = 32\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ur-wMMyMa6nT",
        "outputId": "8b4e1f7c-7785-4209-e88c-57cb0cb7c126"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total = len(annotations)\n",
        "train_size = int(0.8 * total)\n",
        "val_size = total - train_size\n",
        "\n",
        "train_subset, val_subset = random_split(annotations, [train_size, val_size])\n",
        "\n",
        "train_ann = list(train_subset)\n",
        "val_ann = list(val_subset)\n",
        "\n",
        "print(\"Total anotaciones:\", total)\n",
        "print(\"Train:\", len(train_ann))\n",
        "print(\"Val:\", len(val_ann))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kxd7jubobvCK",
        "outputId": "494b8e4f-2fce-4866-b864-b8bb545718cc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total anotaciones: 13320\n",
            "Train: 10656\n",
            "Val: 2664\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_labels = sorted(list({ann[\"label\"] for ann in (train_ann + val_ann)}))\n",
        "print(\"Total de clases:\", len(all_labels))\n",
        "\n",
        "used_labels = all_labels\n",
        "\n",
        "label_to_idx = {lbl: i for i, lbl in enumerate(used_labels)}\n",
        "idx_to_label = {i: lbl for lbl, i in label_to_idx.items()}\n",
        "\n",
        "print(\"Ejemplo mapeo:\", list(label_to_idx.items())[:10])\n",
        "\n"
      ],
      "metadata": {
        "id": "o7E5bBUXbz6I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5957a3a6-4a51-46df-ed14-8d9e49a58d46"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total de clases: 101\n",
            "Ejemplo mapeo: [(0, 0), (1, 1), (2, 2), (3, 3), (4, 4), (5, 5), (6, 6), (7, 7), (8, 8), (9, 9)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SkeletonDataset(Dataset):\n",
        "    def __init__(self, annotations_list, label_to_idx, max_frames=60, use_first_person=True, used_labels=None):\n",
        "        self.max_frames = max_frames\n",
        "        self.label_to_idx = label_to_idx\n",
        "        self.use_first_person = use_first_person\n",
        "        self.used_labels = set(used_labels) if used_labels is not None else None\n",
        "\n",
        "        self.samples = []\n",
        "        for ann in annotations_list:\n",
        "            lbl = ann[\"label\"]\n",
        "            if self.used_labels is not None and lbl not in self.used_labels:\n",
        "                continue\n",
        "            if lbl not in self.label_to_idx:\n",
        "                continue\n",
        "            self.samples.append(ann)\n",
        "\n",
        "        print(\"Total de muestras:\", len(self.samples))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def _process_keypoint(self, keypoint):\n",
        "        keypoint = keypoint[0]\n",
        "        T, V, C = keypoint.shape\n",
        "\n",
        "        if T >= self.max_frames:\n",
        "            keypoint = keypoint[:self.max_frames]\n",
        "        else:\n",
        "            pad_len = self.max_frames - T\n",
        "            pad = np.zeros((pad_len, V, C), dtype=keypoint.dtype)\n",
        "            keypoint = np.concatenate([keypoint, pad], axis=0)\n",
        "\n",
        "        keypoint = keypoint.reshape(self.max_frames, V * C)\n",
        "        return keypoint\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        ann = self.samples[idx]\n",
        "        keypoint = self._process_keypoint(ann[\"keypoint\"])\n",
        "        seq = torch.from_numpy(keypoint).float()\n",
        "        label = self.label_to_idx[ann[\"label\"]]\n",
        "        return seq, label\n",
        "\n"
      ],
      "metadata": {
        "id": "-G0ivLrjcZnw"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_FRAMES = 60\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_dataset = SkeletonDataset(\n",
        "    annotations_list=train_ann,\n",
        "    label_to_idx=label_to_idx,\n",
        "    max_frames=MAX_FRAMES,\n",
        "    use_first_person=True,\n",
        "    used_labels=used_labels\n",
        ")\n",
        "\n",
        "val_dataset = SkeletonDataset(\n",
        "    annotations_list=val_ann,\n",
        "    label_to_idx=label_to_idx,\n",
        "    max_frames=MAX_FRAMES,\n",
        "    use_first_person=True,\n",
        "    used_labels=used_labels\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "batch_x, batch_y = next(iter(train_loader))\n",
        "print(\"Batch X shape:\", batch_x.shape)\n",
        "print(\"Batch Y shape:\", batch_y.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOLe1amNb6M4",
        "outputId": "d31eb6d8-a318-4ba1-df6c-33b541b679bf"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total de muestras: 10656\n",
            "Total de muestras: 2664\n",
            "Batch X shape: torch.Size([32, 60, 34])\n",
            "Batch Y shape: torch.Size([32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = SkeletonDataset(\n",
        "    annotations_list=train_ann,\n",
        "    label_to_idx=label_to_idx,\n",
        "    max_frames=MAX_FRAMES,\n",
        "    use_first_person=True,\n",
        "    used_labels=used_labels\n",
        ")\n",
        "\n",
        "val_dataset = SkeletonDataset(\n",
        "    annotations_list=val_ann,\n",
        "    label_to_idx=label_to_idx,\n",
        "    max_frames=MAX_FRAMES,\n",
        "    use_first_person=True,\n",
        "    used_labels=used_labels\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "batch_x, batch_y = next(iter(train_loader))\n",
        "print(\"Batch X shape:\", batch_x.shape)\n",
        "print(\"Batch Y shape:\", batch_y.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E80_d0SPmtsZ",
        "outputId": "d27b253b-8f00-4ca4-f72c-669cbf39382f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total de muestras: 10656\n",
            "Total de muestras: 2664\n",
            "Batch X shape: torch.Size([32, 60, 34])\n",
            "Batch Y shape: torch.Size([32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim = batch_x.shape[2]\n",
        "num_classes = len(used_labels)\n",
        "\n",
        "class ActionBiLSTM(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, num_layers, num_classes, dropout=0.3):\n",
        "        super().__init__()\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_dim,\n",
        "            hidden_dim,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True,\n",
        "            dropout=dropout,\n",
        "            bidirectional=True\n",
        "        )\n",
        "        self.fc = nn.Linear(hidden_dim * 2, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, (h_n, c_n) = self.lstm(x)\n",
        "        h_forward = h_n[-2]\n",
        "        h_backward = h_n[-1]\n",
        "        h_cat = torch.cat((h_forward, h_backward), dim=1)\n",
        "        logits = self.fc(h_cat)\n",
        "        return logits\n",
        "\n",
        "hidden_dim = 256\n",
        "num_layers = 2\n",
        "\n",
        "model = ActionBiLSTM(input_dim, hidden_dim, num_layers, num_classes).to(DEVICE)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "print(\"Input dim:\", input_dim)\n",
        "print(\"Num classes:\", num_classes)\n",
        "print(\"Device modelo:\", next(model.parameters()).device)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jCFyatFhmvrx",
        "outputId": "8c4aebef-01c1-4785-db23-fe7df1ceaa68"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input dim: 34\n",
            "Num classes: 101\n",
            "Device modelo: cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(model, dataloader, optimizer, criterion, device):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for x, y in dataloader:\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(x)\n",
        "        loss = criterion(logits, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item() * x.size(0)\n",
        "        preds = logits.argmax(dim=1)\n",
        "        correct += (preds == y).sum().item()\n",
        "        total += y.size(0)\n",
        "\n",
        "    avg_loss = total_loss / total\n",
        "    acc = correct / total\n",
        "    return avg_loss, acc\n",
        "\n",
        "def evaluate(model, dataloader, criterion, device):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in dataloader:\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "\n",
        "            logits = model(x)\n",
        "            loss = criterion(logits, y)\n",
        "\n",
        "            total_loss += loss.item() * x.size(0)\n",
        "            preds = logits.argmax(dim=1)\n",
        "            correct += (preds == y).sum().item()\n",
        "            total += y.size(0)\n",
        "\n",
        "    avg_loss = total_loss / total\n",
        "    acc = correct / total\n",
        "    return avg_loss, acc\n"
      ],
      "metadata": {
        "id": "_LKDP1CEm0jH"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 100\n",
        "\n",
        "history_bi = {\n",
        "    \"train_loss\": [],\n",
        "    \"train_acc\": [],\n",
        "    \"val_loss\": [],\n",
        "    \"val_acc\": []\n",
        "}\n",
        "\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "    train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, criterion, DEVICE)\n",
        "    val_loss, val_acc = evaluate(model, val_loader, criterion, DEVICE)\n",
        "\n",
        "    history_bi[\"train_loss\"].append(train_loss)\n",
        "    history_bi[\"train_acc\"].append(train_acc)\n",
        "    history_bi[\"val_loss\"].append(val_loss)\n",
        "    history_bi[\"val_acc\"].append(val_acc)\n",
        "\n",
        "    print(f\"Epoch {epoch:02d} | \"\n",
        "          f\"Train loss: {train_loss:.4f} acc: {train_acc:.4f} | \"\n",
        "          f\"Val loss: {val_loss:.4f} acc: {val_acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHeGSvoZm2i9",
        "outputId": "97b1e370-d2f3-4754-995e-b33546ea56c0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 01 | Train loss: 3.5450 acc: 0.1199 | Val loss: 3.4997 acc: 0.1126\n",
            "Epoch 02 | Train loss: 3.4478 acc: 0.1319 | Val loss: 3.4127 acc: 0.1329\n",
            "Epoch 03 | Train loss: 3.4248 acc: 0.1288 | Val loss: 3.3764 acc: 0.1434\n",
            "Epoch 04 | Train loss: 3.3325 acc: 0.1498 | Val loss: 3.2863 acc: 0.1535\n",
            "Epoch 05 | Train loss: 3.2795 acc: 0.1562 | Val loss: 3.4746 acc: 0.1250\n",
            "Epoch 06 | Train loss: 3.2205 acc: 0.1635 | Val loss: 3.2909 acc: 0.1607\n",
            "Epoch 07 | Train loss: 3.1630 acc: 0.1799 | Val loss: 3.1873 acc: 0.1682\n",
            "Epoch 08 | Train loss: 3.0593 acc: 0.1949 | Val loss: 3.1546 acc: 0.1918\n",
            "Epoch 09 | Train loss: 3.0027 acc: 0.2064 | Val loss: 3.1634 acc: 0.1689\n",
            "Epoch 10 | Train loss: 2.9785 acc: 0.2080 | Val loss: 3.0804 acc: 0.1877\n",
            "Epoch 11 | Train loss: 2.9222 acc: 0.2242 | Val loss: 3.1560 acc: 0.1783\n",
            "Epoch 12 | Train loss: 2.8801 acc: 0.2349 | Val loss: 3.0223 acc: 0.2050\n",
            "Epoch 13 | Train loss: 2.7951 acc: 0.2465 | Val loss: 3.0652 acc: 0.1967\n",
            "Epoch 14 | Train loss: 2.7333 acc: 0.2631 | Val loss: 3.0005 acc: 0.2196\n",
            "Epoch 15 | Train loss: 2.6884 acc: 0.2734 | Val loss: 3.0509 acc: 0.2005\n",
            "Epoch 16 | Train loss: 2.6386 acc: 0.2833 | Val loss: 3.0209 acc: 0.2128\n",
            "Epoch 17 | Train loss: 2.5807 acc: 0.2891 | Val loss: 2.9390 acc: 0.2252\n",
            "Epoch 18 | Train loss: 2.5340 acc: 0.3119 | Val loss: 3.0053 acc: 0.2173\n",
            "Epoch 19 | Train loss: 2.4394 acc: 0.3368 | Val loss: 2.8779 acc: 0.2500\n",
            "Epoch 20 | Train loss: 2.3755 acc: 0.3534 | Val loss: 2.8804 acc: 0.2417\n",
            "Epoch 21 | Train loss: 2.3344 acc: 0.3594 | Val loss: 2.8829 acc: 0.2541\n",
            "Epoch 22 | Train loss: 2.2681 acc: 0.3783 | Val loss: 2.8329 acc: 0.2744\n",
            "Epoch 23 | Train loss: 2.2006 acc: 0.3913 | Val loss: 2.8545 acc: 0.2673\n",
            "Epoch 24 | Train loss: 2.1631 acc: 0.4005 | Val loss: 2.8440 acc: 0.2661\n",
            "Epoch 25 | Train loss: 2.1562 acc: 0.4059 | Val loss: 2.8486 acc: 0.2721\n",
            "Epoch 26 | Train loss: 2.0666 acc: 0.4264 | Val loss: 2.8361 acc: 0.2823\n",
            "Epoch 27 | Train loss: 2.0229 acc: 0.4433 | Val loss: 2.8009 acc: 0.2890\n",
            "Epoch 28 | Train loss: 2.0163 acc: 0.4437 | Val loss: 2.8106 acc: 0.3037\n",
            "Epoch 29 | Train loss: 1.9445 acc: 0.4644 | Val loss: 2.8554 acc: 0.2827\n",
            "Epoch 30 | Train loss: 1.8954 acc: 0.4765 | Val loss: 2.8247 acc: 0.2995\n",
            "Epoch 31 | Train loss: 1.8869 acc: 0.4789 | Val loss: 2.8647 acc: 0.2857\n",
            "Epoch 32 | Train loss: 1.8107 acc: 0.4947 | Val loss: 2.8138 acc: 0.3059\n",
            "Epoch 33 | Train loss: 1.7673 acc: 0.5063 | Val loss: 2.9454 acc: 0.2883\n",
            "Epoch 34 | Train loss: 1.7710 acc: 0.5065 | Val loss: 2.8454 acc: 0.3078\n",
            "Epoch 35 | Train loss: 1.7295 acc: 0.5165 | Val loss: 2.8778 acc: 0.2950\n",
            "Epoch 36 | Train loss: 1.6963 acc: 0.5241 | Val loss: 2.8247 acc: 0.3146\n",
            "Epoch 37 | Train loss: 1.6739 acc: 0.5244 | Val loss: 2.8146 acc: 0.3228\n",
            "Epoch 38 | Train loss: 1.6497 acc: 0.5360 | Val loss: 2.8201 acc: 0.3232\n",
            "Epoch 39 | Train loss: 1.6382 acc: 0.5404 | Val loss: 2.9145 acc: 0.2988\n",
            "Epoch 40 | Train loss: 1.6139 acc: 0.5367 | Val loss: 2.8252 acc: 0.3217\n",
            "Epoch 41 | Train loss: 1.5897 acc: 0.5480 | Val loss: 2.8305 acc: 0.3292\n",
            "Epoch 42 | Train loss: 1.5509 acc: 0.5595 | Val loss: 2.9141 acc: 0.3213\n",
            "Epoch 43 | Train loss: 1.4890 acc: 0.5750 | Val loss: 2.7951 acc: 0.3457\n",
            "Epoch 44 | Train loss: 1.4491 acc: 0.5870 | Val loss: 2.7676 acc: 0.3453\n",
            "Epoch 45 | Train loss: 1.4441 acc: 0.5884 | Val loss: 2.9302 acc: 0.3307\n",
            "Epoch 46 | Train loss: 1.4011 acc: 0.6022 | Val loss: 2.8702 acc: 0.3405\n",
            "Epoch 47 | Train loss: 1.3764 acc: 0.6065 | Val loss: 2.8696 acc: 0.3510\n",
            "Epoch 48 | Train loss: 1.4293 acc: 0.5928 | Val loss: 2.9066 acc: 0.3382\n",
            "Epoch 49 | Train loss: 1.3814 acc: 0.6030 | Val loss: 2.8362 acc: 0.3585\n",
            "Epoch 50 | Train loss: 1.3752 acc: 0.5984 | Val loss: 2.8880 acc: 0.3506\n",
            "Epoch 51 | Train loss: 1.3422 acc: 0.6146 | Val loss: 2.8956 acc: 0.3532\n",
            "Epoch 52 | Train loss: 1.3441 acc: 0.6092 | Val loss: 2.8867 acc: 0.3536\n",
            "Epoch 53 | Train loss: 1.3234 acc: 0.6109 | Val loss: 2.8440 acc: 0.3619\n",
            "Epoch 54 | Train loss: 1.3161 acc: 0.6166 | Val loss: 2.8226 acc: 0.3705\n",
            "Epoch 55 | Train loss: 1.3029 acc: 0.6241 | Val loss: 3.0274 acc: 0.3393\n",
            "Epoch 56 | Train loss: 1.3183 acc: 0.6147 | Val loss: 2.9267 acc: 0.3495\n",
            "Epoch 57 | Train loss: 1.2885 acc: 0.6280 | Val loss: 2.9542 acc: 0.3566\n",
            "Epoch 58 | Train loss: 1.3095 acc: 0.6177 | Val loss: 2.9488 acc: 0.3529\n",
            "Epoch 59 | Train loss: 1.2831 acc: 0.6232 | Val loss: 3.0093 acc: 0.3412\n",
            "Epoch 60 | Train loss: 1.2276 acc: 0.6409 | Val loss: 2.9173 acc: 0.3566\n",
            "Epoch 61 | Train loss: 1.2138 acc: 0.6458 | Val loss: 2.9419 acc: 0.3585\n",
            "Epoch 62 | Train loss: 1.1935 acc: 0.6525 | Val loss: 3.0440 acc: 0.3506\n",
            "Epoch 63 | Train loss: 1.1848 acc: 0.6521 | Val loss: 2.9558 acc: 0.3731\n",
            "Epoch 64 | Train loss: 1.1704 acc: 0.6521 | Val loss: 3.0394 acc: 0.3562\n",
            "Epoch 65 | Train loss: 1.1594 acc: 0.6577 | Val loss: 2.9793 acc: 0.3589\n",
            "Epoch 66 | Train loss: 1.1253 acc: 0.6702 | Val loss: 3.0193 acc: 0.3675\n",
            "Epoch 67 | Train loss: 1.1254 acc: 0.6669 | Val loss: 2.9654 acc: 0.3690\n",
            "Epoch 68 | Train loss: 1.1263 acc: 0.6701 | Val loss: 3.0499 acc: 0.3577\n",
            "Epoch 69 | Train loss: 1.1245 acc: 0.6680 | Val loss: 2.9757 acc: 0.3746\n",
            "Epoch 70 | Train loss: 1.0582 acc: 0.6832 | Val loss: 2.9875 acc: 0.3885\n",
            "Epoch 71 | Train loss: 1.0635 acc: 0.6850 | Val loss: 3.0074 acc: 0.3712\n",
            "Epoch 72 | Train loss: 1.0336 acc: 0.6888 | Val loss: 2.9332 acc: 0.3810\n",
            "Epoch 73 | Train loss: 1.0320 acc: 0.6867 | Val loss: 2.8803 acc: 0.3926\n",
            "Epoch 74 | Train loss: 1.0101 acc: 0.6968 | Val loss: 3.0022 acc: 0.3806\n",
            "Epoch 75 | Train loss: 0.9767 acc: 0.7070 | Val loss: 2.9559 acc: 0.3780\n",
            "Epoch 76 | Train loss: 0.9826 acc: 0.7014 | Val loss: 2.9676 acc: 0.3911\n",
            "Epoch 77 | Train loss: 1.0343 acc: 0.6908 | Val loss: 3.0066 acc: 0.3878\n",
            "Epoch 78 | Train loss: 0.9688 acc: 0.7071 | Val loss: 3.0113 acc: 0.3998\n",
            "Epoch 79 | Train loss: 0.9338 acc: 0.7167 | Val loss: 2.9815 acc: 0.3930\n",
            "Epoch 80 | Train loss: 0.9732 acc: 0.7050 | Val loss: 3.0252 acc: 0.3851\n",
            "Epoch 81 | Train loss: 0.9471 acc: 0.7134 | Val loss: 3.0833 acc: 0.3773\n",
            "Epoch 82 | Train loss: 0.9329 acc: 0.7185 | Val loss: 3.0031 acc: 0.3908\n",
            "Epoch 83 | Train loss: 0.9159 acc: 0.7205 | Val loss: 3.0468 acc: 0.3911\n",
            "Epoch 84 | Train loss: 0.9128 acc: 0.7247 | Val loss: 2.9967 acc: 0.3949\n",
            "Epoch 85 | Train loss: 0.9200 acc: 0.7199 | Val loss: 3.1221 acc: 0.3859\n",
            "Epoch 86 | Train loss: 0.8709 acc: 0.7335 | Val loss: 3.0843 acc: 0.3979\n",
            "Epoch 87 | Train loss: 0.8704 acc: 0.7290 | Val loss: 3.0773 acc: 0.4050\n",
            "Epoch 88 | Train loss: 0.8557 acc: 0.7384 | Val loss: 3.0069 acc: 0.4170\n",
            "Epoch 89 | Train loss: 0.8537 acc: 0.7371 | Val loss: 3.0988 acc: 0.3930\n",
            "Epoch 90 | Train loss: 0.8598 acc: 0.7381 | Val loss: 3.1316 acc: 0.3911\n",
            "Epoch 91 | Train loss: 0.8382 acc: 0.7418 | Val loss: 3.0253 acc: 0.4118\n",
            "Epoch 92 | Train loss: 0.7898 acc: 0.7587 | Val loss: 3.0943 acc: 0.4032\n",
            "Epoch 93 | Train loss: 0.7936 acc: 0.7562 | Val loss: 3.1846 acc: 0.3953\n",
            "Epoch 94 | Train loss: 0.7847 acc: 0.7571 | Val loss: 3.0715 acc: 0.4114\n",
            "Epoch 95 | Train loss: 0.7762 acc: 0.7608 | Val loss: 3.0733 acc: 0.4080\n",
            "Epoch 96 | Train loss: 0.7722 acc: 0.7631 | Val loss: 3.1238 acc: 0.3979\n",
            "Epoch 97 | Train loss: 0.7742 acc: 0.7649 | Val loss: 3.1216 acc: 0.3945\n",
            "Epoch 98 | Train loss: 0.7474 acc: 0.7666 | Val loss: 3.1620 acc: 0.3810\n",
            "Epoch 99 | Train loss: 0.7573 acc: 0.7670 | Val loss: 3.1229 acc: 0.3923\n",
            "Epoch 100 | Train loss: 0.7843 acc: 0.7633 | Val loss: 3.1157 acc: 0.4095\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este proyecto se implementó un modelo de reconocimiento de acciones utilizando el dataset UCF101 en su versión de esqueletos 2D, lo cual reduce la información visual a coordenadas de articulaciones. El modelo baseline, basado en un LSTM unidireccional con dimensión oculta de 128, alcanzó alrededor de 14% de accuracy en validación, superando ampliamente el azar (~1%) en un problema de 101 clases, demostrando que incluso con información reducida es posible aprender patrones temporales significativos.\n",
        "\n",
        "Posteriormente, se mejoró la arquitectura utilizando un BiLSTM con mayor capacidad (hidden_dim=256) y un entrenamiento extendido, alcanzando aproximadamente 40% de accuracy en validación. Esta mejora evidencia que incrementar la complejidad del modelo y permitir el flujo bidireccional de información beneficia el desempeño en tareas de secuencias. Los resultados finales muestran un aprendizaje sólido dentro de las limitaciones del formato esquelético y cumplen con los objetivos del portafolio."
      ],
      "metadata": {
        "id": "9FFxlAwLoSTi"
      }
    }
  ]
}